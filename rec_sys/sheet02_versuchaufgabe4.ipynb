{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a)\n",
    "\n",
    "If the maximum Degree is N for one variable, than it can be in the polynomial part as {0,1,...,N} variants.\n",
    "THis means that there are (N_x + 1 ) * (N_Y + 1)  * ( N_z + 1) possible  combinations of these variables resulting in the same amount of coefficients.\n",
    "\n",
    "Version 1: t * 4 (x,y,z, and coeff)\n",
    "\n",
    "Version 2:This would result in an three dimensional matrix having the shape ((N_x + 1 ), (N_Y + 1),( N_z + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import rec_sys.jax_intro as jax_intro\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import time\n",
    "import random\n",
    "rnd_seed = int(time.time())\n",
    "rnd_key = jax.random.PRNGKey(rnd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  1]\n",
      " [ 2  0  2  1]\n",
      " [ 3  0  2  4]\n",
      " [ 1  0  1 -3]\n",
      " [ 2  0  0 -5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gen_polynomial(Nx,Ny,Nz,t):\n",
    "    \n",
    "    max_arr = [Nx,Ny,Nz]\n",
    "    \n",
    "    \n",
    "    indx = jax.random.randint(  rnd_key, (t,3), jnp.zeros((t,3)),\n",
    "                                jnp.reshape(jnp.repeat(jnp.array([Nx+1,Ny+1,Nz+1]),repeats=t,axis=0 ),\n",
    "                                newshape=(3,t)).T)\n",
    "    \n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        if max(indx[:,i])< max_arr[i] :\n",
    "            rnd_indx = random.randint(0, t-1)\n",
    "            indx = indx.at[rnd_indx,i].set(max_arr[i]) \n",
    "    LIM = 5\n",
    "    rnd_coeff = jax.random.randint(  rnd_key, (t,1), -LIM * jnp.ones((t,1)),\n",
    "                                    LIM * jnp.ones((t,1))\n",
    "                                     )\n",
    "    coeff_mat = jnp.hstack([indx,rnd_coeff])\n",
    "    return(coeff_mat)\n",
    "\n",
    "\n",
    "\n",
    "def f(x,y,z,polym):\n",
    "    res = jnp.zeros(x.shape[0])\n",
    "    for i in range(polym.shape[0]):\n",
    "        res += polym[i,3] * jnp.power(x,polym[i,0])* jnp.power(y,polym[i,1])* jnp.power(z,polym[i,2])\n",
    "    return(res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_noisy_set(N,coeff_mat):\n",
    "    noise_frac, rnd_seed =  0.25, int(time.time())\n",
    "    x,y,z = jnp.linspace(-3, 3,N),jnp.linspace(-3, 3,N),jnp.linspace(-3, 3,N)\n",
    "    res_pure = f(x,y,z,coeff_mat)\n",
    "    # Add some noise to data\n",
    "    rnd_key = jax.random.PRNGKey(rnd_seed)\n",
    "    y_with_noise = res_pure + res_pure * noise_frac * jax.random.normal(rnd_key, (N,))\n",
    "    return x,y,z,y_with_noise\n",
    "\n",
    "polym = gen_polynomial(3,1,2,5)\n",
    "print(polym)\n",
    "#print(generate_noisy_set(10,polym) )\n",
    "\n",
    "#print(generate_noisy_set(2,jnp.array([[1,1,1,1],[0,0,0,0]])) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_polynomial2(Nx,Ny,Nz,t):\n",
    "    LIM = 3\n",
    "    rnd_seed = int(time.time())\n",
    "    max_arr = [Nx,Ny,Nz]\n",
    "\n",
    "    coeff_mat = jnp.zeros((Nx+1,Ny+1,Nz+1))\n",
    "    for _ in range(t):\n",
    "        rnd_coeff = random.randint(-LIM,LIM)\n",
    "        while rnd_coeff ==0:\n",
    "            rnd_coeff = random.randint(-LIM,LIM)\n",
    "        coeff_mat = coeff_mat.at[random.randint(0,Nx),random.randint(0,Ny),random.randint(0,Nz)].set(rnd_coeff) \n",
    "\n",
    "\n",
    "    while not jnp.any(coeff_mat[-1,:,:]):\n",
    "        coeff_mat = jnp.roll(coeff_mat,1,0)\n",
    "    while not jnp.any(coeff_mat[:,-1,:]):\n",
    "        coeff_mat = jnp.roll(coeff_mat,1,1)\n",
    "    while not jnp.any(coeff_mat[...,-1]):\n",
    "        coeff_mat = jnp.roll(coeff_mat,1,2)\n",
    "    return coeff_mat\n",
    "\n",
    "\n",
    "def f2(x,y,z,polym):\n",
    "    res = jnp.zeros(x.shape[0])\n",
    "    for i in range(polym.shape[0]):\n",
    "        for j in range(polym.shape[1]):\n",
    "            for k in range(polym.shape[2]):\n",
    "                res += polym[i,j,k] * jnp.power(x,i)* jnp.power(y,j)* jnp.power(z,k)\n",
    "    return(res)\n",
    "\n",
    "def generate_noisy_set2(N,coeff_mat):\n",
    "    noise_frac, rnd_seed =  0.25, int(time.time())\n",
    "    x,y,z = jnp.linspace(-3, 3,N),jnp.linspace(-3, 3,N),jnp.linspace(-3, 3,N)\n",
    "    res_pure = f2(x,y,z,coeff_mat)\n",
    "    # Add some noise to data\n",
    "\n",
    "    res_with_noise = res_pure + res_pure * noise_frac * jax.random.normal(rnd_key, (N,))\n",
    "    return x,y,z,res_with_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running Stochastic Gradient Descent =====\n",
      "Epoch 0: param_w=[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]], grad=[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]], loss=nan\n",
      "Epoch 1: param_w=[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]], grad=[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]], loss=nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m    \u001b[38;5;28mprint\u001b[39m(polynomial)\n\u001b[0;32m     39\u001b[0m    \u001b[38;5;28mprint\u001b[39m(param_w)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolym2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m, in \u001b[0;36mSGD\u001b[1;34m(polynomial, Nx, Ny, Nz, t)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, train_set_size, num_points_per_batch):\n\u001b[0;32m     32\u001b[0m     batch \u001b[38;5;241m=\u001b[39m train_ds[:,i:i \u001b[38;5;241m+\u001b[39m num_points_per_batch]\n\u001b[1;32m---> 33\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     param_w \u001b[38;5;241m=\u001b[39m param_w \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m grad\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: param_w=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_w\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, grad=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss(param_w,\u001b[38;5;250m \u001b[39mtrain_ds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\api.py:659\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 659\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m value_and_grad_f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    660\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\api.py:741\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    739\u001b[0m _check_scalar(ans)\n\u001b[0;32m    740\u001b[0m tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n\u001b[1;32m--> 741\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    742\u001b[0m g \u001b[38;5;241m=\u001b[39m g[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m g\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\tree_util.py:357\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m--> 357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\api.py:2148\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[1;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[0;32m   2143\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(arg) \u001b[38;5;241m!=\u001b[39m ct_shape:\n\u001b[0;32m   2144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cotangent input to vjp pullback function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2148\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\tree_util.py:357\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m--> 357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:149\u001b[0m, in \u001b[0;36mvjp.<locals>.unbound_vjp\u001b[1;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[0;32m    147\u001b[0m cts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval\u001b[38;5;241m.\u001b[39mis_known())\n\u001b[0;32m    148\u001b[0m dummy_args \u001b[38;5;241m=\u001b[39m [UndefinedPrimal(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars]\n\u001b[1;32m--> 149\u001b[0m arg_cts \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(instantiate_zeros, arg_cts)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\interpreters\\ad.py:253\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[0;32m    250\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m get_primitive_transpose(eqn\u001b[38;5;241m.\u001b[39mprimitive)(\n\u001b[0;32m    251\u001b[0m       params, call_jaxpr, invals, cts_in, cts_in_avals, reduce_axes)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39mprimitive \u001b[38;5;129;01min\u001b[39;00m reducing_transposes:\n\u001b[1;32m--> 253\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m reducing_transposes[eqn\u001b[38;5;241m.\u001b[39mprimitive](\n\u001b[0;32m    254\u001b[0m       reduce_axes, cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m get_primitive_transpose(eqn\u001b[38;5;241m.\u001b[39mprimitive)(\n\u001b[0;32m    257\u001b[0m       cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\pjit.py:1748\u001b[0m, in \u001b[0;36m_pjit_transpose\u001b[1;34m(reduce_axes, cts_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *primals_in)\u001b[0m\n\u001b[0;32m   1742\u001b[0m cts_out_treedef \u001b[38;5;241m=\u001b[39m cts_out_treedef_thunk()\n\u001b[0;32m   1743\u001b[0m transpose_out_shardings \u001b[38;5;241m=\u001b[39m prune_type(\n\u001b[0;32m   1744\u001b[0m     ad\u001b[38;5;241m.\u001b[39mZero,\n\u001b[0;32m   1745\u001b[0m     in_shardings,\n\u001b[0;32m   1746\u001b[0m     tree_unflatten(cts_out_treedef, [\u001b[38;5;28mobject\u001b[39m()] \u001b[38;5;241m*\u001b[39m cts_out_treedef\u001b[38;5;241m.\u001b[39mnum_leaves))\n\u001b[1;32m-> 1748\u001b[0m nz_cts_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals_and_nz_cts_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_in_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_out_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprimals_and_nz_cts_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(cts_out_treedef, nz_cts_out)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[0;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[0;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[1;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[1;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\Aaron Maekel\\.conda\\envs\\MMD\\lib\\site-packages\\jax\\_src\\pjit.py:1245\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[1;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[0;32m   1242\u001b[0m donated_argnums \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(donated_invars) \u001b[38;5;28;01mif\u001b[39;00m d]\n\u001b[0;32m   1243\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[0;32m   1244\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "#polynomials:\n",
    "polym1 = gen_polynomial(2,4,6,12)\n",
    "polym2 = gen_polynomial(3,1,2,5)\n",
    "\n",
    "def SGD(polynomial,Nx,Ny,Nz,t):\n",
    "\n",
    "    # %% Run the SG loop\n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.05\n",
    "    train_set_size = 10000\n",
    "    train_ds  = jnp.asarray(generate_noisy_set(train_set_size ,polynomial))\n",
    "    \n",
    "    param_w = gen_polynomial(Nx,Ny,Nz,t).astype(float)  # Initial guess for the parameter\n",
    "\n",
    "    # %% Define a simple loss function and its gradient\n",
    "    def loss(param_w, data):\n",
    "        # return  jnp.sum((data[:,1] - f(data[:,0], param_w))**2)\n",
    "        res = f(data[0],data[1],data[2], param_w)\n",
    "\n",
    "        return jnp.log(jnp.sum((data[3] - res) ** 2)) \n",
    "\n",
    "\n",
    "    # Using JAX automatic differentiation - autograd\n",
    "    grad_loss = jax.grad(loss)#,allow_int=True)\n",
    "\n",
    "    num_points_per_batch = train_set_size // 5\n",
    "    print(\"\\n===== Running Stochastic Gradient Descent =====\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Get points for the current batch\n",
    "        for i in range(0, train_set_size, num_points_per_batch):\n",
    "            batch = train_ds[:,i:i + num_points_per_batch]\n",
    "            grad = grad_loss(param_w, batch)\n",
    "            param_w = param_w - learning_rate * grad\n",
    "\n",
    "        print(f\"Epoch {epoch}: param_w={param_w}, grad={grad}, loss={loss(param_w, train_ds)}\")\n",
    "\n",
    "    print(polynomial)\n",
    "    print(param_w)\n",
    "SGD(polym2,3,1 ,2,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  3.  0.]\n",
      "  [ 0.  2.  0.]]\n",
      "\n",
      " [[ 0. -3.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  3.]]]\n",
      "\n",
      "===== Running Stochastic Gradient Descent =====\n",
      "Epoch 0:  loss=21.97057342529297\n",
      "Epoch 1:  loss=21.860944747924805\n",
      "Epoch 2:  loss=21.738082885742188\n",
      "Epoch 3:  loss=21.601057052612305\n",
      "Epoch 4:  loss=21.44331169128418\n",
      "Epoch 5:  loss=21.2585506439209\n",
      "Epoch 6:  loss=21.037555694580078\n",
      "Epoch 7:  loss=20.768587112426758\n",
      "Epoch 8:  loss=20.44303321838379\n",
      "Epoch 9:  loss=20.087587356567383\n",
      "Epoch 10:  loss=19.78936767578125\n",
      "Epoch 11:  loss=19.600202560424805\n",
      "Epoch 12:  loss=19.47283172607422\n",
      "Epoch 13:  loss=19.42186164855957\n",
      "Epoch 14:  loss=19.374752044677734\n",
      "Epoch 15:  loss=19.36151885986328\n",
      "Epoch 16:  loss=19.33759117126465\n",
      "Epoch 17:  loss=19.330074310302734\n",
      "Epoch 18:  loss=19.323762893676758\n",
      "Epoch 19:  loss=19.31654167175293\n",
      "Epoch 20:  loss=19.31874656677246\n",
      "Epoch 21:  loss=19.30645751953125\n",
      "Epoch 22:  loss=19.308258056640625\n",
      "Epoch 23:  loss=19.29726791381836\n",
      "Epoch 24:  loss=19.29850959777832\n",
      "Epoch 25:  loss=19.289186477661133\n",
      "Epoch 26:  loss=19.28838539123535\n",
      "Epoch 27:  loss=19.28485870361328\n",
      "Epoch 28:  loss=19.29046630859375\n",
      "Epoch 29:  loss=19.283842086791992\n",
      "Epoch 30:  loss=19.286638259887695\n",
      "Epoch 31:  loss=19.27904510498047\n",
      "Epoch 32:  loss=19.28218650817871\n",
      "Epoch 33:  loss=19.27532958984375\n",
      "Epoch 34:  loss=19.27884864807129\n",
      "Epoch 35:  loss=19.272668838500977\n",
      "Epoch 36:  loss=19.276391983032227\n",
      "Epoch 37:  loss=19.27089500427246\n",
      "Epoch 38:  loss=19.273576736450195\n",
      "Epoch 39:  loss=19.26796531677246\n",
      "Epoch 40:  loss=19.27100372314453\n",
      "Epoch 41:  loss=19.26593780517578\n",
      "Epoch 42:  loss=19.269229888916016\n",
      "Epoch 43:  loss=19.264610290527344\n",
      "Epoch 44:  loss=19.268075942993164\n",
      "Epoch 45:  loss=19.264028549194336\n",
      "Epoch 46:  loss=19.266117095947266\n",
      "Epoch 47:  loss=19.261640548706055\n",
      "Epoch 48:  loss=19.263648986816406\n",
      "Epoch 49:  loss=19.259872436523438\n",
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  3.  0.]\n",
      "  [ 0.  2.  0.]]\n",
      "\n",
      " [[ 0. -3.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  3.]]]\n",
      "[[[ 0.04241379 -0.01314322  0.49279597]\n",
      "  [-0.01314322  0.49279597 -0.1315259 ]]\n",
      "\n",
      " [[-0.01314322  0.49279597 -0.1315259 ]\n",
      "  [ 0.49279597 -0.1315259   0.25857875]]\n",
      "\n",
      " [[ 0.49279597 -0.13152587  0.2585788 ]\n",
      "  [-0.13152587  0.2585788  -0.0250751 ]]\n",
      "\n",
      " [[-0.13152589  0.2585788  -0.02507509]\n",
      "  [ 0.2585788  -0.0250751   2.686824  ]]]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#polynomials:\n",
    "polym1 = gen_polynomial2(2,4,6,12)\n",
    "polym2 = gen_polynomial2(3,1,2,5)\n",
    "print(polym2)\n",
    "def SGD(polynomial,Nx,Ny,Nz,t):\n",
    "\n",
    "    # %% Run the SG loop\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.05\n",
    "    train_set_size = 10000\n",
    "    train_ds  = jnp.asarray(generate_noisy_set2(train_set_size ,polynomial))\n",
    "    \n",
    "    param_w = jnp.zeros((Nx+1,Ny+1,Nz+1)) #gen_polynomial2(Nx,Ny,Nz,t).astype(float)  # Initial guess for the parameter\n",
    "\n",
    "    # %% Define a simple loss function and its gradient\n",
    "    def loss(param_w, data):\n",
    "        # return  jnp.sum((data[:,1] - f(data[:,0], param_w))**2)\n",
    "        res = f2(data[0],data[1],data[2], param_w)\n",
    "      \n",
    "        return jnp.log(jnp.sum((data[3] - res) ** 2)) \n",
    "\n",
    "    # Using JAX automatic differentiation - autograd\n",
    "    grad_loss = jax.grad(loss)\n",
    "\n",
    "    num_points_per_batch = train_set_size // 5\n",
    "    print(\"\\n===== Running Stochastic Gradient Descent =====\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Get points for the current batch\n",
    "        for i in range(0, train_set_size, num_points_per_batch):\n",
    "            batch = train_ds[:,i:i + num_points_per_batch]\n",
    "            grad = grad_loss(param_w, batch)\n",
    "            param_w = param_w - learning_rate * grad\n",
    "\n",
    "        print(f\"Epoch {epoch}:  loss={loss(param_w, train_ds)}\")\n",
    "    print(polynomial)\n",
    "    print(param_w)\n",
    "SGD(polym2,3,1,2,5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
