{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMD 2024, Problem Sheet 2: Latent Factor Models\n",
    "\n",
    "Group: Daniela Fichiu, Aaron Maekel, Manuel Senger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "The following table shows a utility matrix with ratings on a 1-5 star scale of eight items, a through h, by three users, A, B and C.\n",
    "\n",
    "|   | a | b | c | d | e | f | g | h |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| A | 4 | 5 |   | 5 | 1 |   | 3 | 2 |\n",
    "| B |   | 3 | 4 | 3 | 1 | 2 | 1 |   |\n",
    "| C | 2 |   | 1 | 3 |   | 4 | 5 | 3 |\n",
    "\n",
    "Perform the following tasks. Submit only your results (no code, even if you have used any).\n",
    "\n",
    "a) **Task:** Treating each blank entry in the utility matrix as 0, compute the cosine distance between each pair of users.\n",
    "\n",
    "**Solution:** \n",
    "The cosine distance is defined as $1 -$ the cosine similarity. Therefore, we first compute the dot products between the vectors and their norms, and then the cosine similarites.\n",
    "\n",
    "Norms: \n",
    "- $\\Vert A \\Vert_2 = (4^2 + 5^2 + 5^2 + 1 + 3^2 + 2^2)^{1/2} \\approx 9$\n",
    "- $\\Vert B \\Vert_2 = (3^2 + 4^2 + 3^2 + 1 + 2^2 + 1)^{1/2} \\approx 6$\n",
    "- $\\Vert C \\Vert_2 = (2^2 + 1 + 3^2 + 4^2 + 5^2 + 3^2)^{1/2} = 8$\n",
    "\n",
    "Dot products:\n",
    "- $ A \\cdot B = (4 \\cdot 0 + 5 \\cdot 3 + 0 \\cdot 4 + 5 \\cdot 3 + 1 \\cdot 1 + 0 \\cdot 2 + 3 \\cdot 1 + 2 \\cdot 0) = 34$\n",
    "- $ A \\cdot C = (4 \\cdot 2 + 5 \\cdot 0 + 0 \\cdot 1 + 5 \\cdot 3 + 1 \\cdot 0 + 0 \\cdot 4 + 3 \\cdot 5 + 2 \\cdot 3) = 44$\n",
    "- $ B \\cdot C = (0 \\cdot 2 + 3 \\cdot 0 + 4 \\cdot 1 + 3 \\cdot 3 + 1 \\cdot 0 + 2 \\cdot 4 + 1 \\cdot 5 + 0 \\cdot 3) = 26$\n",
    "\n",
    "Cosine similarities:\n",
    "- $\\cos_\\text{sim}(A, B) = A \\cdot B / \\Vert A \\Vert_2 \\Vert B \\Vert_2 = 34 / 9 \\cdot 6 \\approx 0.6$\n",
    "- $\\cos_\\text{sim}(A, C) = A \\cdot C / \\Vert A \\Vert_2 \\Vert C \\Vert_2 = 44 / 9 \\cdot 8 \\approx 0.6$\n",
    "- $\\cos_\\text{sim}(B, C) = B \\cdot C / \\Vert B \\Vert_2 \\Vert C \\Vert_2 = 26 / 6 \\cdot 8 \\approx 0.55$\n",
    "\n",
    "Cosiene distances:\n",
    "- $\\cos_\\text{dist}(A, B) = 1 - \\cos_\\text{sim}(A, B) \\approx 1 - 0.6 \\approx 0.4$\n",
    "- $\\cos_\\text{dist}(A, C) = 1 - \\cos_\\text{sim}(A, C) \\approx 1 - 0.6 \\approx 0.4$\n",
    "- $\\cos_\\text{dist}(B, C) = 1 - \\cos_\\text{sim}(B, C) \\approx 1 - 0.55 \\approx 0.45$\n",
    "\n",
    "\n",
    "b) **Task:** Treating ratings of 3, 4, and 5 as 1 and 1, 2, and blank as 0, compute the cosine distance between each pair of users. Compare these results to those obtain in Part a).\n",
    "\n",
    "**Solution:** Converting 3 and 4 to 1 and 5 to 2, we obtain the following utility matrix:\n",
    "\n",
    "\n",
    "|   | a | b | c | d | e | f | g | h |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| A | 1 | 2 |   | 2 | 1 |   | 1 | 2 |\n",
    "| B |   | 1 | 1 | 1 | 1 | 2 | 1 |   |\n",
    "| C | 2 |   | 1 | 1 |   | 1 | 2 | 1 |\n",
    "\n",
    "For the obtained utility matrix, we repeat the steps from Part a).\n",
    "\n",
    "Norms: \n",
    "- $\\Vert A \\Vert_2 = (1^2 + 2^2 + 2^2 + 1 + 1^2 + 2^2)^{1/2} \\approx 4$\n",
    "- $\\Vert B \\Vert_2 = (1^2 + 1^2 + 1^2 + 1 + 2^2 + 1)^{1/2} \\approx 3$\n",
    "- $\\Vert C \\Vert_2 = (2^2 + 1 + 1^2 + 1^2 + 2^2 + 1^2)^{1/2} \\approx 3.5$\n",
    "\n",
    "Dot products:\n",
    "- $ A \\cdot B = (1 \\cdot 0 + 2 \\cdot 1 + 0 \\cdot 1 + 2 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 2 + 1 \\cdot 1 + 2 \\cdot 0) = 6$\n",
    "- $ A \\cdot C = (1 \\cdot 2 + 2 \\cdot 0 + 0 \\cdot 1 + 2 \\cdot 1 + 1 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 2 + 2 \\cdot 1) = 8$\n",
    "- $ B \\cdot C = (0 \\cdot 2 + 1 \\cdot 0 + 1 \\cdot 1 + 1 \\cdot 1 + 1 \\cdot 0 + 2 \\cdot 1 + 1 \\cdot 2 + 0 \\cdot 1) = 6$\n",
    "\n",
    "Cosine similarities:\n",
    "- $\\cos_\\text{sim}(A, B) = A \\cdot B / \\Vert A \\Vert_2 \\Vert B \\Vert_2 = 6 / 4 \\cdot 3 \\approx 0.5$\n",
    "- $\\cos_\\text{sim}(A, C) = A \\cdot C / \\Vert A \\Vert_2 \\Vert C \\Vert_2 = 8 / 4 \\cdot 3.5 \\approx 0.57$\n",
    "- $\\cos_\\text{sim}(B, C) = B \\cdot C / \\Vert B \\Vert_2 \\Vert C \\Vert_2 = 6 / 3 \\cdot 3.5 \\approx 0.57$\n",
    "\n",
    "Cosine distances:\n",
    "- $\\cos_\\text{dist}(A, B) = 1 - \\cos_\\text{sim}(A, B) \\approx 1 - 0.5 \\approx 0.5$\n",
    "- $\\cos_\\text{dist}(A, C) = 1 - \\cos_\\text{sim}(A, C) \\approx 1 - 0.57 \\approx 0.43$\n",
    "- $\\cos_\\text{dist}(B, C) = 1 - \\cos_\\text{sim}(B, C) \\approx 1 - 0.57 \\approx 0.43$\n",
    "\n",
    "The results obtained are similar to those from Part a). The biggest changes are in the cosine distances of A. This is due to the fact that from the 6 non-blank entries of A (of which two were 5), four got changed.\n",
    "\n",
    "c) **Task:** Normalize the matrix by substracting from each non-blank entry the average value for its user. Then compute the cosine distance between each pair of users (blank entries are treated as 0).\n",
    "\n",
    "**Solution:** We compute the averages only over the existing values:\n",
    "\n",
    "Averages:\n",
    "- $A = \\frac{(4 + 5 + 5 + 1 + 3 + 2)}{6} \\approx 3.3$\n",
    "- $B = \\frac{(3 + 4 + 3 + 1 + 2 + 1)}{6} \\approx 2.3$\n",
    "- $C = \\frac{(2 + 1 + 3 + 4 + 5 + 3)}{6} = 3$\n",
    "\n",
    "The normalized matrix has is then given by\n",
    "\n",
    "\n",
    "|   | a | b | c | d | e | f | g | h |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| A | 0.7 | 1.7 |   | 1.7 | -2.3 |   | -0.3 | -1.3 |\n",
    "| B |   | 0.7 | 1.7 | 0.7 | -1.3 | -0.3 | -1.3 |   |\n",
    "| C | -1 |   | -2 | 0 |   | 1 | 2 | 0 |\n",
    "\n",
    "\n",
    "Norms: \n",
    "- $\\Vert A \\Vert_2 \\approx 3.6$\n",
    "- $\\Vert B \\Vert_2 \\approx 2.7$\n",
    "- $\\Vert C \\Vert_2 \\approx 3.1$\n",
    "\n",
    "Dot products:\n",
    "- $ A \\cdot B \\approx 5.7$\n",
    "- $ A \\cdot C \\approx -1.29$\n",
    "- $ B \\cdot C \\approx -6.3$\n",
    "\n",
    "Cosine similarities:\n",
    "- $\\cos_\\text{sim}(A, B) = A \\cdot B / \\Vert A \\Vert_2 \\Vert B \\Vert_2 = 5.7 / (3.6 \\cdot 2.7) \\approx 0.5$\n",
    "- $\\cos_\\text{sim}(A, C) = A \\cdot C / \\Vert A \\Vert_2 \\Vert C \\Vert_2 = -1.29 / (3.6 \\cdot 3.1) \\approx -0.1$\n",
    "- $\\cos_\\text{sim}(B, C) = B \\cdot C / \\Vert B \\Vert_2 \\Vert C \\Vert_2 = -6.3 / (2.7 \\cdot 3.1) \\approx -0.7$\n",
    "\n",
    "Cosine distances:\n",
    "- $\\cos_\\text{dist}(A, B) = 1 - \\cos_\\text{sim}(A, B) \\approx 1 - 0.5 \\approx 0.5$\n",
    "- $\\cos_\\text{dist}(A, C) = 1 - \\cos_\\text{sim}(A, C) \\approx 1 + 0.1 \\approx 1.1$\n",
    "- $\\cos_\\text{dist}(B, C) = 1 - \\cos_\\text{sim}(B, C) \\approx 1 + 0.7 \\approx 1.7$\n",
    "\n",
    "d) **Task:** Compute the Pearson correlation coefficient between each pair of users as defined in Lecture 1 (slide \"From Cosine to Pearson\"). Compare these results to those obtained in Part c) and state your conclusions.\n",
    "\n",
    "**Solution:** The only difference between the Pearson coefficient and the cosine similarites computed in Part c) is that the Pearson coefficient computes the norm-like denominators over the commonly rated items.\n",
    "\n",
    "Denominators for the cosine similarity between:\n",
    "- $A$ and $B$: $d_{AB} \\approx 7$ (over items b, d, e, g)\n",
    "- $A$ and $C$: $d_{AC} \\approx 5$ (over items a, d, g, h)\n",
    "- $B$ and $C$: $d_{BC} \\approx 7$ (over items c, d, f, g)\n",
    "\n",
    "Cosine similarities:\n",
    "- $\\cos_\\text{sim}(A, B) = A \\cdot B / d_{AB} \\approx 5.7 / 7 \\approx 0.8$\n",
    "- $\\cos_\\text{sim}(A, C) = A \\cdot C / d_{AC} \\approx -1.29 / 5 \\approx -0.2$\n",
    "- $\\cos_\\text{sim}(B, C) = B \\cdot C / d_{BC} \\approx -6.3 / 7 \\approx -0.9$\n",
    "\n",
    "Cosine distances:\n",
    "- $\\cos_\\text{dist}(A, B) = 1 - \\cos_\\text{sim}(A, B) \\approx 1 - 0.8 \\approx 0.2$\n",
    "- $\\cos_\\text{dist}(A, C) = 1 - \\cos_\\text{sim}(A, C) \\approx 1 + 0.2 \\approx 1.2$\n",
    "- $\\cos_\\text{dist}(B, C) = 1 - \\cos_\\text{sim}(B, C) \\approx 1 + 0.9 \\approx 1.9$\n",
    "\n",
    "TODO: Write comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function `uv_factorization_vec_no_reg` from `rec_sys/lf_algorithms.py` and the functions utilized there. Perform the following tasks:\n",
    "\n",
    "a) **Task:** Implement the function `uv_factorization_vec_reg` (along with any necessary helper or sub-functions) which executes the SDG using a loss function with the regularization terms discussed in the lecture. Use one common regularization parameter for both matrices. Test your implementation using the settings from `rec_sys/config.py` (you might need to adjust  some hyperparameters). Then, use the function `show_metrics_and_examples` to compare the convergence and the accuracy of your function against the non-regularizd version of SGD from the original (i.e., repository) code.\n",
    "\n",
    "**Solution:** See `uv_factorization_vec_reg` in `rec_sys/lf_algorithms.py`.\n",
    "\n",
    "b) **Task:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a)\n",
    "The rating of a professor should be divided into multiple categories ( makes a good lecture, is a good supervisor etc.), as tchey an differ a lot. This means, each time a user rates a lecture,seminar, thesis supervision, the rating should only affect the categories it fits best. ( having had a bad thesis supervision is not important for the quality of the lecture the professor will organize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) \n",
    "\n",
    "if the artworks are items, then there should be tags describing the essence of each artwork like {scary,nature,goofy}. These can be used to find out which genres the user prefers and are usable in content recommender systems.\n",
    "\n",
    "A better focus than the artwork may be the artists themselves, If a user likes an artwork he will prefer other art made in the same style, thus being from the same artist, compared to different artwork which may have the same topics, but differ in style. Thus the algorithm should rather try to match user and artist compared to user and picture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)\n",
    "There is no user-item pairing, it is a user-user pairing. This changes the problem dramatically, as both users have to rate each other, thus a bidirectional pairing has to be done. \n",
    "\n",
    " Features could be superficial ( haircolor/weight etc.), personal information(age, religion, etc.) and tastes/dislikes (music genres, food etc.).   \n",
    "\n",
    " \n",
    "Another difficulty is in the aggregation of non-superficial data, as it is hard to put into categories, but may be even the most important data of all. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
