{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMD 2024, Problem Sheet 6\n",
    "\n",
    "Group: Daniela Fichiu, Aaron Maekel, Manuel Senger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "The Jaccard similarity can be applied to sets of elements. Sometimes, documents (or\n",
    "other objects) may be represented as multi-sets/bags rather than sets. In a multi-set,\n",
    "an element can be a member more than once, whereas a set can only hold each element\n",
    "at most once. Try to define a similarity metric for multi-sets. This metric should take\n",
    "exactly the same values as Jaccard similarity in the special case where both multi-sets\n",
    "are in fact sets.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "Remember Jaccard similiarity:\n",
    "I12 := Interception of C1 and C2\n",
    "U12:= Union of C1 and C2\n",
    "sim(C1,C2) = #(I12)/#(U12)\n",
    "\n",
    "\n",
    "Assume we now have multisets with duplicate elements for example MC1= [a,a,b,b,c] and MC2 = [a,b,b,b,c,c,d]\n",
    "\n",
    "Then we can transform each multiset by differentiating each tuple of elements into unique elements by indexing:\n",
    "\n",
    "MC1 = [a1,a2,b1,b2,c1]\n",
    "\n",
    "MC2 = [a1,b1,b2,b3,c1,c2,d1]\n",
    "\n",
    "we can now use Interception and unions as before:\n",
    "\n",
    "#I12 = 4\n",
    "\n",
    "#U12 = 8\n",
    "\n",
    "sim(MC1,MC2) = 0.5\n",
    "\n",
    "This metric is equivalent to the jaccard similiarity if both inputs are normal sets, because the transformation will not change anything, except for renaming the set elements. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set up the Spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    value|\n",
      "+---------+\n",
      "|WHEN A DI|\n",
      "|HEN A DIS|\n",
      "|EN A DIST|\n",
      "|N A DISTI|\n",
      "| A DISTIN|\n",
      "|A DISTING|\n",
      "| DISTINGU|\n",
      "|DISTINGUI|\n",
      "|ISTINGUIS|\n",
      "|STINGUISH|\n",
      "|TINGUISHE|\n",
      "|INGUISHED|\n",
      "|NGUISHED |\n",
      "|GUISHED B|\n",
      "|UISHED BU|\n",
      "|ISHED BUT|\n",
      "|SHED BUT |\n",
      "|HED BUT E|\n",
      "|ED BUT EL|\n",
      "|D BUT ELD|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TExercise2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"shingle\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create an empty DataFrame with the specified schema\n",
    "\n",
    "\n",
    "def get_shingles(file,k=9):\n",
    "    with open(os.path.join(\"Task6Ex2_documents\",  file), 'r') as file:\n",
    "        txt = file.read().replace(\"-\\n\",\"\").replace(\"\\n\",\"\").upper()\n",
    "     \n",
    "    \n",
    "    df = spark.createDataFrame([], schema)\n",
    "    shingles ={} \n",
    "    for i in range(len(txt)-k):\n",
    "        subtext = txt[i:i+k]\n",
    "\n",
    "        if subtext not in shingles.keys():\n",
    "            shingles[subtext] = True\n",
    "    \n",
    "\n",
    "       \n",
    "    df = spark.createDataFrame( data= shingles, schema=StringType())\n",
    "    \n",
    "    return df, df.count()\n",
    "\n",
    "\n",
    " \n",
    "# Create a DataFrame from the list of tuples\n",
    "#df = spark.read.option(\"delimiter\", \"\").text(os.path.join(\"Task6Ex2_documents\",  \"example_txt.txt\")) \n",
    "#df = df.withColumn(\"value\",explode(split('value','')))\n",
    "#df.show()\n",
    "\n",
    "\n",
    " \n",
    "df , n = get_shingles(\"example_txt.txt\")\n",
    "df.show()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of 5-shingles 23830\n",
      "Amount of 9-shingles 81060\n"
     ]
    }
   ],
   "source": [
    "df,n5 = get_shingles(\"grundgesetz.txt\",5) \n",
    "df,n9 = get_shingles(\"grundgesetz.txt\",9) \n",
    "#print(df.rdd.takeSample(False, 30))\n",
    "print(\"Amount of 5-shingles\",n5)\n",
    "print(\"Amount of 9-shingles\",n9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for checking 10 different documents, we just split the grundgesetz into 10 different parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grundgesetz Part 1  Amount of  5 -shingles: 6827\n",
      "Grundgesetz Part 1  Amount of  9 -shingles: 12873\n",
      "Grundgesetz Part 2  Amount of  5 -shingles: 6337\n",
      "Grundgesetz Part 2  Amount of  9 -shingles: 12203\n",
      "Grundgesetz Part 3  Amount of  5 -shingles: 6309\n",
      "Grundgesetz Part 3  Amount of  9 -shingles: 12140\n",
      "Grundgesetz Part 4  Amount of  5 -shingles: 6650\n",
      "Grundgesetz Part 4  Amount of  9 -shingles: 12297\n",
      "Grundgesetz Part 5  Amount of  5 -shingles: 5632\n",
      "Grundgesetz Part 5  Amount of  9 -shingles: 11023\n",
      "Grundgesetz Part 6  Amount of  5 -shingles: 5975\n",
      "Grundgesetz Part 6  Amount of  9 -shingles: 11708\n",
      "Grundgesetz Part 7  Amount of  5 -shingles: 5628\n",
      "Grundgesetz Part 7  Amount of  9 -shingles: 10812\n",
      "Grundgesetz Part 8  Amount of  5 -shingles: 6080\n",
      "Grundgesetz Part 8  Amount of  9 -shingles: 11539\n",
      "Grundgesetz Part 9  Amount of  5 -shingles: 6020\n",
      "Grundgesetz Part 9  Amount of  9 -shingles: 11443\n",
      "Grundgesetz Part 10  Amount of  5 -shingles: 6223\n",
      "Grundgesetz Part 10  Amount of  9 -shingles: 11503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    for k in [5,9]:\n",
    "        _,n = get_shingles(\"grundgesetz_\"+str(i+1)+\".txt\",k) \n",
    "        print(\"Grundgesetz Part\", i+1 , \" Amount of \",k,\"-shingles:\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** \n",
    "\n",
    "Figure 1 shows a table (or matrix) representing four sets S1, S2, S3 and S4 (subsets of\n",
    "{0, 1, 2, 3, 4, 5})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Task:**\n",
    "\n",
    "Compute the MinHash signature for each set using the following three hash functions:\n",
    "\n",
    "h1(x) = 2x + 1 mod 6\n",
    "\n",
    "h2(x) = 3x + 2 mod 6\n",
    "\n",
    "h3(x) = 5x + 2 mod 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minhash( Set 0 ): 0\n",
      "minhash( Set 1 ): 1\n",
      "minhash( Set 2 ): 1\n",
      "minhash( Set 3 ): 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.array([[0,0,1,0,0,1],[1,1,0,0,0,0],[0,0,0,1,1,0],[1,0,1,0,1,0]])\n",
    "\n",
    "def h1(x):\n",
    "    return (2*x + 1 )% 6\n",
    "def h2(x):\n",
    "    return (3*x + 2 )% 6\n",
    "def h3(x):\n",
    "    return (5*x + 2 )% 6\n",
    "\n",
    "def give_set(input):\n",
    "    return  np.nonzero(input)[0]\n",
    "\n",
    "def minhash(matrix):\n",
    "    for i in range(4):\n",
    "        set = give_set(matrix[i])\n",
    "        \n",
    "        \n",
    "        print(\"minhash( Set\",i,\"):\",min(min(h1(set)),min(h2(set)),min(h3(set))))\n",
    "        \n",
    "\n",
    "minhash(matrix)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** \n",
    "\n",
    "Which of these hash functions are true permutations? What collisions do occur in\n",
    "the other hash functions? Name the corresponding inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0 1 2 3 4 5]\n",
      "output of hash function 1 [1 3 5 1 3 5]\n",
      "output of hash function 2 [2 5 2 5 2 5]\n",
      "output of hash function 3 [2 1 0 5 4 3]\n"
     ]
    }
   ],
   "source": [
    "test =np.array([0,1,2,3,4,5])\n",
    "print(\"input:\",test)\n",
    "print(\"output of hash function 1\",h1(test))\n",
    "print(\"output of hash function 2\",h2(test))\n",
    "print(\"output of hash function 3\",h3(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, only the third hash function is a true permutation, as the other two are not bijective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **Task:** \n",
    "\n",
    "Compare the similarity of the MinHash signatures against the corresponding Jaccard\n",
    "similarities, for each of the   6 pairs of columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column 0  and column 1  have minhash sim: 0.0\n",
      "column 0  and column 1  have jacard sim: 0.0\n",
      "column 0  and column 2  have minhash sim: 0.0\n",
      "column 0  and column 2  have jacard sim: 0.0\n",
      "column 0  and column 3  have minhash sim: 0.25\n",
      "column 0  and column 3  have jacard sim: 0.25\n",
      "column 1  and column 2  have minhash sim: 0.0\n",
      "column 1  and column 2  have jacard sim: 0.0\n",
      "column 1  and column 3  have minhash sim: 0.25\n",
      "column 1  and column 3  have jacard sim: 0.25\n",
      "column 2  and column 3  have minhash sim: 0.25\n",
      "column 2  and column 3  have jacard sim: 0.25\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "PERMS = set(permutations( [0,1,2,3,4,5]))\n",
    "\n",
    "\n",
    "def minhash2(vec,perm):\n",
    "     \n",
    "    return min(np.array(perm)[give_set(vec)])\n",
    "    \n",
    "def jaccard_sim(c1,c2):\n",
    "    \n",
    "    return np.sum(np.logical_and(c1,c2))/np.sum(np.logical_or(c1,c2))\n",
    "\n",
    "def minhash_sim(c1,c2):\n",
    "    prob = 0\n",
    "    for i in PERMS:\n",
    "        prob += minhash2(c1,i)==minhash2(c2,i)\n",
    "    prob /= len(PERMS)\n",
    "    return prob\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(1,4-i):\n",
    "        \n",
    "        print(\"column\",i,\" and column\",i+j,\" have minhash sim:\", minhash_sim(matrix[i],matrix[i+j]))\n",
    "        print(\"column\",i,\" and column\",i+j,\" have jacard sim:\", jaccard_sim(matrix[i],matrix[i+j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the both similiarity functions are the same,as it should be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Recall the concepts of Shingling and MinHash signatures to perform the following tasks.\n",
    "Submit as your solution your source code, results, and logs of runs. You do not need to\n",
    "take care of the scalability of your code, e.g., assume that all input/output data fit into\n",
    "RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Task:**\n",
    "\n",
    "Implement a routine in Python to compute a representation of a string of decimal\n",
    "digits (0...9) as a set of k-shingles. The input of your routine is a string of digits\n",
    "and k. The output is an ordered list of positions of 1’s in a (virtual) Boolean\n",
    "representation of a set of k-shingles as outlined in Lecture 7 (see slide “From Sets\n",
    "to Boolean Matrices”). The position of a k-shingle x (of digits) in the Boolean\n",
    "vector is x interpreted as an integer. For example, shingles “0...00” and “0...2024”\n",
    "would map to (decimal) positions 0 and 2024, respectively. Moreover, for a string\n",
    "“1234567” and k = 4 your routine should output the list [1234, 2345, 3456, 4567].\n",
    "Hint: You can use Python’s data structure set() (or as alternative dict()) to\n",
    "need just one pass through the input string plus outputting the positions in an\n",
    "ordered fashion.\n",
    "\n",
    "b) **Task:** \n",
    "\n",
    "Run your implementation from a) on the first 10000 digits of π after comma using\n",
    "k = 12. Save the output list as a text file with one position (list element) per line,\n",
    "and submit it as a part of your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   313783875    407854733    422966171 ... 999983729780 999998372978\n",
      " 999999837297]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_shingles_dec(txt,k):\n",
    "    \n",
    "    shingles ={} \n",
    "    for i in range(len(txt)-k):\n",
    "        #remove trailing zeros by converting it to int.\n",
    "        subtext = str(int(txt[i:i+k]))\n",
    "\n",
    "        if subtext not in shingles.keys():\n",
    "            shingles[subtext] = True\n",
    "    unsorted_pos = [int(x) for x in shingles.keys()]\n",
    "\n",
    "    return np.sort(unsorted_pos)\n",
    "\n",
    "with open( \"pi.txt\" , 'r') as file:\n",
    "    txt = file.read().replace(\" \",\"\").replace(\".\",\"\")\n",
    "    \n",
    "shingles = get_shingles_dec(txt,12)\n",
    "\n",
    "print(shingles)\n",
    "\n",
    "with open(r'pi_shingles.txt', 'w') as fp:\n",
    "    for item in shingles:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we only have 9999 digits of pi, I am sorry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **Task:** \n",
    "\n",
    "Implement (in Python) the algorithm for MinHash signatures as described in the\n",
    "slides “Implementation /*” of Lecture 7. We simplify here and assume only one\n",
    "column C representing one document/string. Thus, your algorithm shall use as\n",
    "input a single list of positions of 1s in a (virtual) Boolean vector described in a).\n",
    "Run your implementation on the list of positions obtained in b) using 5 hash\n",
    "functions, specified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature: [2.49166640e+07 1.04714586e+08 1.81477250e+07 3.18072120e+07\n",
      " 2.58758930e+07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "N = 10**12  \n",
    "#print(\"N:\",N)\n",
    "\n",
    "A = np.array([37, random.getrandbits(40), random.getrandbits(40), random.getrandbits(40), random.getrandbits(40)], dtype=np.longdouble)\n",
    "B = np.array([126, random.getrandbits(40),random.getrandbits(40), random.getrandbits(40), random.getrandbits(40)], dtype=np.longdouble)\n",
    "P = (10*np.ones(5))**15 + np.array([223,37, 91, 159, 187])\n",
    "\n",
    "def h(x,a=37,b=126,p=(10**15 + 223)):\n",
    "    #print(\"a:\",a)\n",
    "    #print(\"b:\",b)\n",
    "    #print(\"X:\",x)\n",
    "    #print(\"ax+b:\" ,(a*x)+b)\n",
    "    #print(\"mod p\",np.mod((a*x+b) , p))\n",
    "    #print(\"mod N\",np.mod(np.mod(a*x+b , p) , N))\n",
    "    return np.mod(np.mod(a*x+b,p), N) + 1\n",
    "\n",
    "arr = np.ones(5)*float(\"inf\")\n",
    "for i in   range(len(shingles)):\n",
    "    for j in range(5):\n",
    "        res= h(shingles[i], A[j],B[j],P[j])\n",
    "        if res < arr[j]:\n",
    "            arr[j] = res \n",
    "arr.astype(np.int64)\n",
    "       \n",
    "print(\"Signature:\" ,arr)    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to avoid integer overflows we used np.longdouble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
